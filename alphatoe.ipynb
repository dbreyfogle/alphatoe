{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaToe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \"\"\"A tic-tac-toe board defined in RL terms\"\"\"\n",
    "\n",
    "    def __init__(self, turn, state=np.zeros((3, 3))):\n",
    "        \"\"\"Setup a 3 x 3 board as an array and specify who's going first\n",
    "        1 ~ X, -1 ~ O, 0 ~ ''\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.turn = turn\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets to empty\"\"\"\n",
    "        self.state = np.zeros((3, 3))\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"Return the current state\"\"\"\n",
    "        return self.state\n",
    "\n",
    "    def set_state(self, state):\n",
    "        \"\"\"Set the current state\"\"\"\n",
    "        self.state = state\n",
    "\n",
    "    def get_turn(self):\n",
    "        \"\"\"Return who's turn it is (+/- 1 for X/O)\"\"\"\n",
    "        return self.turn\n",
    "\n",
    "    def set_turn(self, turn):\n",
    "        \"\"\"Set who's turn it is\"\"\"\n",
    "        self.turn = turn\n",
    "\n",
    "    def display(self, state=None):\n",
    "        \"\"\"\n",
    "            0   1   2\n",
    "          *---*---*---*\n",
    "        0 | X | O | X |\n",
    "          *---*---*---*\n",
    "        1 |   | X | O |\n",
    "          *---*---*---*\n",
    "        2 | X |   | O |\n",
    "          *---*---*---*\n",
    "        \"\"\"\n",
    "        if state is None: state = self.state\n",
    "        to_txt = {0: ' ', 1: 'X', -1: 'O'}\n",
    "        print('    0   1   2')\n",
    "        print('  *---*---*---*')\n",
    "        for row in range(3):\n",
    "            row_str = '{} | '.format(row)\n",
    "            for col in range(3):\n",
    "                mark = state[row, col]\n",
    "                row_str += '{} | '.format(to_txt[mark])\n",
    "            print(row_str)\n",
    "            print('  *---*---*---*')\n",
    "\n",
    "    def is_full(self, state=None):\n",
    "        \"\"\"Checks if the board is full\"\"\"\n",
    "        if state is None: state = self.state\n",
    "        for row in range(3):\n",
    "            for col in range(3):\n",
    "                if state[row, col] == 0: # Any empty space\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def get_actions(self, state=None):\n",
    "        \"\"\"Return a list of actions that can be taken in the given state, i.e.\n",
    "        the indices of empty spaces (row, col)\n",
    "        \"\"\"\n",
    "        if state is None: state = self.state\n",
    "        actions = []\n",
    "        for row in range(3):\n",
    "            for col in range(3):\n",
    "                if state[row, col] == 0:\n",
    "                    actions.append((row, col))\n",
    "        return actions\n",
    "\n",
    "    def get_rewards(self, state=None):\n",
    "        \"\"\"Return rewards for each player given the state (X reward, O reward)\"\"\"\n",
    "        if state is None: state = self.state\n",
    "        for i in range(3):\n",
    "            this_row_sum = np.sum(state[i, :])\n",
    "            this_col_sum = np.sum(state[:, i])\n",
    "            if this_row_sum == 3 or this_col_sum == 3: return 1, -1\n",
    "            if this_row_sum == -3 or this_col_sum == -3: return -1, 1\n",
    "        diag1_sum = np.trace(state)\n",
    "        diag2_sum = np.trace(np.fliplr(state))\n",
    "        if diag1_sum == 3 or diag2_sum == 3: return 1, -1\n",
    "        if diag1_sum == -3 or diag2_sum == -3: return -1, 1\n",
    "        return 0, 0\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Perform an action and return the new state and any rewards\"\"\"\n",
    "        assert self.state[action[0], action[1]] == 0, 'Environment tried to process an invalid action'\n",
    "        self.state[action[0], action[1]] = self.turn\n",
    "        rewards = self.get_rewards()\n",
    "        self.turn *= -1\n",
    "        is_done = False\n",
    "        if rewards[0] or self.is_full():\n",
    "            is_done = True\n",
    "        return self.state, rewards, is_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"AlphaToe\"\"\"\n",
    "\n",
    "    def __init__(self, mark, state=np.zeros((3, 3))):\n",
    "        \"\"\"Spawn a q-learning agent. Must provide the X/O mark (+/- 1). Current state is\n",
    "        optional and will default to an empty board\n",
    "        \"\"\"\n",
    "        self.mark = mark\n",
    "        self.state = state\n",
    "        self.model = {1: {}, -1: {}} # States, actions, q-values\n",
    "        self.prev_act = None\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Resets back to a new game\"\"\"\n",
    "        self.state = np.zeros((3, 3))\n",
    "    \n",
    "    def evaluate(self, state=None, mark=None):\n",
    "        \"\"\"Return a table of explored actions and q-values for the given state\"\"\"\n",
    "        if state is None: state = self.state\n",
    "        if mark is None: mark = self.mark\n",
    "        state_key = tuple(self.state.flatten())\n",
    "        return self.model[mark][state_key]\n",
    "\n",
    "    def act(self, env, e=0.1):\n",
    "        \"\"\"Take an action in the Environment. Larger epsilon values encourage exploration where random\n",
    "        actions are taken epsilon percent of the time\n",
    "        \"\"\"\n",
    "        m = self.mark\n",
    "        s = tuple(self.state.flatten())\n",
    "        choices = env.get_actions()\n",
    "        if e > random.uniform(0, 1): # Explore\n",
    "            a = random.choice(choices)\n",
    "        else: # Exploit\n",
    "            try:\n",
    "                Q = self.evaluate()\n",
    "                a = max(Q, key=Q.get)\n",
    "            except: a = random.choice(choices)\n",
    "        s1, R, d = env.step(a)\n",
    "        self.prev_act = a\n",
    "        if m == 1: r = R[0]\n",
    "        else: r = R[1]\n",
    "        return s1, r, d\n",
    "\n",
    "    def observe(self, s1, r, d, lr=0.3, y=0.5):\n",
    "        \"\"\"\"\"\"\n",
    "        m = self.mark\n",
    "        s = tuple(self.state.flatten())\n",
    "        a = self.prev_act\n",
    "        if s not in self.model[m]:\n",
    "            self.model[m][s] = {}\n",
    "        try:\n",
    "            Q = self.evaluate(s1)\n",
    "            q_next = max(Q.values())\n",
    "        except: q_next = 0\n",
    "        try: q_curr = self.model[m][s][a]\n",
    "        except: q_curr = 0\n",
    "        self.model[m][s][a] = q_curr + lr * (r + (y * q_next) - q_curr)\n",
    "        self.state = s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human():\n",
    "    \"\"\"For playing against AlphaToe\"\"\"\n",
    "\n",
    "    def __init__(self, mark):\n",
    "        self.mark = mark\n",
    "\n",
    "    def act(self, env):\n",
    "        \"\"\"Ask for next move and update the board\"\"\"\n",
    "        env.display()\n",
    "        print('Your turn:')\n",
    "        is_invalid = True\n",
    "        while is_invalid:\n",
    "            row = int(input('Row #: '))\n",
    "            col = int(input('Column #: '))\n",
    "            try:\n",
    "                if env.get_state()[row, col] == 0: # Must exist and be empty\n",
    "                    is_invalid = False\n",
    "            except:\n",
    "                print('Sorry, that spot is taken or out of bounds. Please try again:')\n",
    "        return (row, col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
